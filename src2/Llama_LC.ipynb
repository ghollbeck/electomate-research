{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Remove the OPENAI_API_KEY from the environment\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "# Retrieve the API key from the environment variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check if the API key is retrieved successfully\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please ensure the .env file contains the OPENAI_API_KEY.\")\n",
    "\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDFs from the folder...\n",
      "Loaded 81 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs (1/81):   0%|          | 0/81 [00:00<?, ?pdf/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1 Metadata:\n",
      "File: politikwechsel-fuer-deutschland-wahlprogramm-von-cdu-csu-1.pdf\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Type: manifesto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs (2/81):   2%|▏         | 2/81 [00:01<00:39,  1.98pdf/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 2 Metadata:\n",
      "File: politikwechsel-fuer-deutschland-wahlprogramm-von-cdu-csu-1.pdf\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Type: manifesto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs (3/81):   4%|▎         | 3/81 [00:02<00:55,  1.40pdf/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 3 Metadata:\n",
      "File: politikwechsel-fuer-deutschland-wahlprogramm-von-cdu-csu-1.pdf\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Type: manifesto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs (4/81):   5%|▍         | 4/81 [00:03<01:03,  1.21pdf/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 4 Metadata:\n",
      "File: politikwechsel-fuer-deutschland-wahlprogramm-von-cdu-csu-1.pdf\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Type: manifesto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs (5/81):   6%|▌         | 5/81 [00:04<01:07,  1.12pdf/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 5 Metadata:\n",
      "File: politikwechsel-fuer-deutschland-wahlprogramm-von-cdu-csu-1.pdf\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Type: manifesto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs (6/81):   7%|▋         | 6/81 [00:05<01:09,  1.07pdf/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 6 Metadata:\n",
      "File: politikwechsel-fuer-deutschland-wahlprogramm-von-cdu-csu-1.pdf\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Type: manifesto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs (7/81):   9%|▊         | 7/81 [00:06<01:10,  1.04pdf/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 7 Metadata:\n",
      "File: politikwechsel-fuer-deutschland-wahlprogramm-von-cdu-csu-1.pdf\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Type: manifesto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs (7/81):   9%|▊         | 7/81 [00:06<01:11,  1.04pdf/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing interrupted by user. Saving progress...\n",
      "Generated 13 nodes (chunks) from the documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:root:Removing unpickleable private attribute _client\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the index to the directory using pickle...\n",
      "Index saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Define chunk size parameters\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "def analyze_document_metadata(text_chunks, llm, max_retries=3):\n",
    "    \"\"\"Analyze document chunks to determine party and document type using LLM.\"\"\"\n",
    "    system_prompt = \"\"\"You are an expert in German political documents. Analyze the given text and determine:\n",
    "    1. The German political party this document belongs to\n",
    "    2. Whether this is a party manifesto or OTHER type of document\n",
    "    \n",
    "    Return your analysis in JSON format with two fields:\n",
    "    - party: The full name of the German political party\n",
    "    - doc_type: Either \"manifesto\" or \"OTHER\"\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_text = \"\\n\".join(text_chunks[:3])  # Use first 3 chunks\n",
    "    user_prompt = f\"Analyze this text from a German political document:\\n\\n{combined_text}\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = llm.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "                timeout=30  # Add timeout parameter\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                metadata = json.loads(response.choices[0].message.content)\n",
    "                return metadata\n",
    "            except json.JSONDecodeError:\n",
    "                if attempt == max_retries - 1:\n",
    "                    return {\"party\": \"Unknown\", \"doc_type\": \"Unknown\"}\n",
    "                time.sleep(2)  # Wait before retrying\n",
    "                \n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"Error analyzing document: {str(e)}\")\n",
    "                return {\"party\": \"Unknown\", \"doc_type\": \"Unknown\"}\n",
    "            time.sleep(2)  # Wait before retrying\n",
    "\n",
    "# Load PDFs\n",
    "print(\"Loading PDFs from the folder...\")\n",
    "pdf_folder = '../downloaded_pdfs'\n",
    "reader = SimpleDirectoryReader(pdf_folder, filename_as_id=True)\n",
    "documents = reader.load_data()\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "\n",
    "# Initialize parser and LLM\n",
    "parser = SimpleNodeParser.from_defaults(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "llm = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "nodes = []\n",
    "# Progress bar showing processed PDFs count\n",
    "with tqdm(total=len(documents), desc=f\"Processing PDFs (0/{len(documents)})\", unit=\"pdf\") as pdf_pbar:\n",
    "    for i, doc in enumerate(documents, 1):\n",
    "        try:\n",
    "            # First get chunks for the document\n",
    "            doc_nodes = parser.get_nodes_from_documents([doc])\n",
    "            \n",
    "            # Get text from first 3 chunks for analysis\n",
    "            chunk_texts = [node.text for node in doc_nodes[:3]]\n",
    "            \n",
    "            # Analyze document using LLM with retry logic\n",
    "            #metadata = analyze_document_metadata(chunk_texts, llm)\n",
    "            \n",
    "            # Add metadata to each node\n",
    "            for node in doc_nodes:\n",
    "                node.metadata = {\n",
    "                    \"file_name\": doc.metadata.get(\"file_name\", \"Unknown\"),\n",
    "                    # \"party\": metadata[\"party\"],\n",
    "                    # \"doc_type\": metadata[\"doc_type\"]\n",
    "                    \"party\": \"Christian Democratic Union and Christian Social Union\",\n",
    "                    \"doc_type\": \"manifesto\"\n",
    "                }\n",
    "            nodes.extend(doc_nodes)\n",
    "            \n",
    "            # Print metadata for each document\n",
    "            print(f\"\\nDocument {i} Metadata:\")\n",
    "            print(f\"File: {doc.metadata.get('file_name', 'Unknown')}\")\n",
    "            print(f\"Party: Christian Democratic Union and Christian Social Union\")\n",
    "            print(f\"Type: manifesto\")\n",
    "            \n",
    "            pdf_pbar.set_description(f\"Processing PDFs ({i}/{len(documents)})\")\n",
    "            pdf_pbar.update(1)\n",
    "            \n",
    "            # Add small delay between API calls\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nProcessing interrupted by user. Saving progress...\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing document {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(f\"Generated {len(nodes)} nodes (chunks) from the documents.\")\n",
    "index = VectorStoreIndex(nodes)\n",
    "\n",
    "# Define the directory for saving embeddings\n",
    "embeddings_directory = \"./embeddings\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(embeddings_directory):\n",
    "    print(f\"Creating directory for embeddings at {embeddings_directory}...\")\n",
    "    os.makedirs(embeddings_directory)\n",
    "\n",
    "# Save the index to the directory using pickle\n",
    "print(\"Saving the index to the directory using pickle...\")\n",
    "with open(os.path.join(embeddings_directory, 'index.pkl'), 'wb') as f:\n",
    "    pickle.dump(index, f)\n",
    "print(\"Index saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the language model...\n",
      "Language model setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Define system message for LLM\n",
    "SYSTEM_MESSAGE = \"\"\"You are an expert political analyst specializing in German politics and policy.\n",
    "Your role is to analyze political documents and provide clear, factual insights about their content, \n",
    "focusing on party positions, policy proposals, and ideological stances.\n",
    "Base your responses strictly on the provided document context rather than general knowledge.\n",
    "Be objective and precise in your analysis.\"\"\"\n",
    "\n",
    "# Define query function\n",
    "def query_index(query):\n",
    "    print(f\"Querying the index with: {query}\")\n",
    "    query_engine = index.as_query_engine(\n",
    "        llm=llm,\n",
    "        similarity_top_k=4,  # Specify how many chunks to retrieve\n",
    "        system_prompt=SYSTEM_MESSAGE\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    \n",
    "    # Print metadata from source nodes\n",
    "    print(\"\\nSource Document Metadata:\")\n",
    "    for idx, source_node in enumerate(response.source_nodes):\n",
    "        print(f\"\\nSource {idx + 1}:\")\n",
    "        print(f\"Party: {source_node.node.metadata.get('party', 'Unknown')}\")\n",
    "        print(f\"Document Type: {source_node.node.metadata.get('doc_type', 'Unknown')}\")\n",
    "        print(f\"Score: {source_node.score}\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "# LLM setup\n",
    "class QueryModel(BaseModel):\n",
    "    query: str\n",
    "\n",
    "print(\"Setting up the language model...\")\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "print(\"Language model setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying the index with: What is the main topic of the document?\n",
      "\n",
      "Source Document Metadata:\n",
      "\n",
      "Source 1:\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Document Type: manifesto\n",
      "Score: 0.7813683702128842\n",
      "\n",
      "Source 2:\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Document Type: manifesto\n",
      "Score: 0.7725054737388198\n",
      "\n",
      "Source 3:\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Document Type: manifesto\n",
      "Score: 0.7719914901034813\n",
      "\n",
      "Source 4:\n",
      "Party: Christian Democratic Union and Christian Social Union\n",
      "Document Type: manifesto\n",
      "Score: 0.77194446728305\n",
      "Query response received:\n",
      "The main topic of the document is a political manifesto outlining the Christian Democratic Union and Christian Social Union's plan for a political change in Germany. It covers various areas such as economic prosperity, security, social justice, and international relations, with a focus on improving the country's future in terms of freedom, peace, and societal cohesion.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example query\n",
    "query = 'What is the main topic of the document?'\n",
    "response = query_index(query)\n",
    "print(\"Query response received:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "electomate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
